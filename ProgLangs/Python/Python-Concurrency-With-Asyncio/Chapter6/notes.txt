6.1: Introducting Multiprocessing library
-------------------------
- can spawn new processes that will each have their own GIL
    - both concurrent and parallel
- need the __name__ == "__main__" or else there will be an exception thrown
    - prevent others who may import your code from accidentally launching multiple processes
- awkward because we have to use use start() and join()

6.2: Using process pools
-------------------------
- process pools are a connection of python processes that we can use to run functions in parallel
    -when we have cpu bound function, we ask pool to run it for us
    - it cleans up the resources when it is done
    - automatically creates processes equal tot he number of cpu cores on the machine you are running
        - can change this but the default is usually good
- use the apply method to run function in seperate process
- although, the apply function blocks 
- can use apply_async so we do not block
    - returns Asyncresult instantly
    - can use get method to block and obtain result of function call

6.3 Using process pool executors with asyncio
-------------------------
- python offers abstraction on top of multiprocessing process pool
    - concurrent.futures model
    - contains executors for both processes and threads that can be used on their own but also interoperate with asyncio
- concurrent.futures provides this abstraction for us with the Executor abstract class
    - two methods for running work asynchronously
        - submit: take a callable and return a Future, equivlane tot pool.apply_async
        - map: take a callable and a list of function arguments and the execute each argumetn in the list asynchronously
            - returns iterator of the results of our calls
- once we have pool, can use method on asyncio loop called run_in_executor
    - take a callable alongside an executor and will run that callable inside the pool
    - returns an awaitable that we can await of pass into function such as gather

6.4: Solving a problem with MapReduce using asyncio
-------------------------
- mapreduce
    - break data down into sets, apply map function, then apply reduce to combine

6.5: Shared data and locks
-------------------------
- multiprocesing supports a concept called shared memory objects
    - chunk of memory allocated that a set of separate processes can access
    - each process can read and write into that memory space
- multiprocessing supports two kinds of shared data: values and array
    - value is single value
    - array is an array of singular values
- can lead to race conditions
    - occurs when the outcome of a set of operations is dependant on which operation finishes first
- can avoid race conditions by syncrhonizing acces to any shared data we want to modify
    - explcity block operation running until the first one completes
- lock (mutex) can be used for synchronization
    - can lock a section of a code, usually called critical sections
    - acquire the lock and release the lock
- process pool executors keep a queue of tasks to manage the tasks
    - when we submit a task to pool, its arguments are pickled and put on task queue
    - then each worker process pulls a task of the queue, unpickles the args, and then executres it
- can use process pool initializer to put shared counter in global variable and let workers know about it

6.6: Multiple processes, multiple event loops
-------------------------
- multiprocesses have soem benefits for I/O bound tasks

























